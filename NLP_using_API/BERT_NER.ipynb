{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coC2k1xc3HWf",
    "outputId": "26a8c4d9-774e-45c5-e075-be7f30393e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLK7Y1jiNXDa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBWYr-hwJQ4i",
    "outputId": "6ecf21da-e3aa-4d16-fe87-dc3777f0cb1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wE1AUu7ZJhRm"
   },
   "outputs": [],
   "source": [
    "path_data = '/ner_dataset.csv'\n",
    "path = '/Bert_Base_Cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvSTWFm7Ukji"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "mCKmz4SAbI_m",
    "outputId": "ef61e9c6-c523-453e-d37f-83ff7695b2d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>war</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demand</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>troops</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #           Word  POS    Tag\n",
       "0   Sentence: 1      Thousands  NNS      O\n",
       "1   Sentence: 1             of   IN      O\n",
       "2   Sentence: 1  demonstrators  NNS      O\n",
       "3   Sentence: 1           have  VBP      O\n",
       "4   Sentence: 1        marched  VBN      O\n",
       "5   Sentence: 1        through   IN      O\n",
       "6   Sentence: 1         London  NNP  B-geo\n",
       "7   Sentence: 1             to   TO      O\n",
       "8   Sentence: 1        protest   VB      O\n",
       "9   Sentence: 1            the   DT      O\n",
       "10  Sentence: 1            war   NN      O\n",
       "11  Sentence: 1             in   IN      O\n",
       "12  Sentence: 1           Iraq  NNP  B-geo\n",
       "13  Sentence: 1            and   CC      O\n",
       "14  Sentence: 1         demand   VB      O\n",
       "15  Sentence: 1            the   DT      O\n",
       "16  Sentence: 1     withdrawal   NN      O\n",
       "17  Sentence: 1             of   IN      O\n",
       "18  Sentence: 1        British   JJ  B-gpe\n",
       "19  Sentence: 1         troops  NNS      O"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path_data, encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riOztP-8NXHT",
    "outputId": "2be7db9d-8552-45d5-ef34-9ca4a5ae8e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tags in corpus: 17\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique tags in corpus:\", data['Tag'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1SRWHM0MJFH_",
    "outputId": "7fe1bb12-f827-411a-ea98-a9cc382f0b9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "num_tags = len(tags)\n",
    "num_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9D9JEzUbdnS"
   },
   "source": [
    "### Task 3: Retrieve Sentences and Corresponsing Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdJst_g5NYY_"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMUQLppspkPj"
   },
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhiSTt2UdzYC",
    "outputId": "0e107c64-e9ef-4d8b-b732-6bb06e60aa34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvENHO18pkaQ"
   },
   "outputs": [],
   "source": [
    "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
    "tag2idx['[PAD]'] = 0\n",
    "target_vocab = len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KADE5bc2oTHk",
    "outputId": "b8a2b2b5-6e44-4e7a-ce07-3ac227d5aa5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,\n",
       " {'B-art': 1,\n",
       "  'B-eve': 2,\n",
       "  'B-geo': 16,\n",
       "  'B-gpe': 4,\n",
       "  'B-nat': 9,\n",
       "  'B-org': 5,\n",
       "  'B-per': 3,\n",
       "  'B-tim': 14,\n",
       "  'I-art': 11,\n",
       "  'I-eve': 15,\n",
       "  'I-geo': 10,\n",
       "  'I-gpe': 17,\n",
       "  'I-nat': 12,\n",
       "  'I-org': 8,\n",
       "  'I-per': 6,\n",
       "  'I-tim': 7,\n",
       "  'O': 13,\n",
       "  '[PAD]': 0})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab, tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "R44g5T7NYp_H",
    "outputId": "a8c9a421-ebdc-46a2-b82c-1c67d7164dfe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in sentences], bins=100) # Length of sentences\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_WaD3K43hXl",
    "outputId": "f8a1f108-2b44-4a16-f790-caab00bfd98e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sentences = [[w[0] for w in s] for s in sentences]\n",
    "training_labels = [[w[2] for w in s] for s in sentences]\n",
    "num_samples = len(training_sentences[:10000])\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wSKYfdwwcWX"
   },
   "outputs": [],
   "source": [
    "training_sentences = training_sentences[:num_samples]\n",
    "training_labels = training_labels[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxKici438Zf_"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForTokenClassification\n",
    "\n",
    "# initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', cache_dir=path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ST-wrIH6Mm7D"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels):\n",
    "      tokenized_sentence = ['[CLS]']\n",
    "      labels = ['O']\n",
    "      for word, label in zip(sentence, text_labels):\n",
    "    # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "    # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "    # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "      tokenized_sentence.append('[SEP]')\n",
    "      labels.append('O')\n",
    "      return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ro8-ZDg1CriV"
   },
   "outputs": [],
   "source": [
    "tokenized_texts_and_labels = [tokenize_and_preserve_labels(sent, labs) for sent, labs in zip(training_sentences, training_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOF4HPuOA26K"
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCCJU5D8U_hZ"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN =64\n",
    "X = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
    "                          truncating=\"post\", padding=\"post\")\n",
    "y = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"[PAD]\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")\n",
    "attention_masks = [[int(i != 0.0) for i in j] for j in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_E1km6j8T4G"
   },
   "outputs": [],
   "source": [
    "indxtotag = {t: i for i, t in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9SCQ1OTUEnb"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRKFp3i8ma3U"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(X)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((X, attention_masks, y)).shuffle(BUFFER_SIZE)\n",
    "data = data.batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HgSxtUnpBih",
    "outputId": "f0c1aaca-a5c7-4a38-d0f0-6b2ac517ab11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64) (64, 64) (64, 64)\n"
     ]
    }
   ],
   "source": [
    "for x,y,z in data:\n",
    "    print(x.shape, y.shape, z.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPOpIaUWu9AZ",
    "outputId": "87ee0b97-9c03-4a5c-f883-c21479c81c70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE = num_samples/BATCH_SIZE\n",
    "SPLIT = 0.9\n",
    "SIZE*SPLIT*BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YHfIYGcmi7q"
   },
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "  \n",
    "data = data.map(map_func)\n",
    "\n",
    "train = data.take(int(SIZE*SPLIT))\n",
    "val = data.skip(int(SIZE*SPLIT))\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XT7OrBxrCbZj",
    "outputId": "48664596-9628-4198-9f47-df0d6d0232b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForTokenClassification.from_pretrained(\n",
    "\"bert-base-cased\",\n",
    "num_labels=len(tag2idx),\n",
    "output_attentions = False,\n",
    "output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yc9JexC1MKFP"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmE1QilqLINW"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "  with tf.GradientTape() as tape:\n",
    "    logits = model(inp['input_ids'], token_type_ids=None, attention_mask=inp['attention_mask']).logits\n",
    "    loss = loss_object(tar, logits)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  train_accuracy.update_state(tar, logits)\n",
    "  return loss\n",
    "def val_step(inp, tar):\n",
    "  logits = model(inp['input_ids'], token_type_ids=None, attention_mask=inp['attention_mask']).logits\n",
    "  loss = loss_object(tar, logits)\n",
    "  test_accuracy.update_state(tar, logits)\n",
    "  return loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGCEniHoDpR4",
    "outputId": "7ac80261-2258-45ef-ebdb-126c3bec6159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5362, Accuracy: 0.8937, Val_Loss: 0.1447, Val Accuracy: 0.9602\n",
      "Time taken for 1 epoch: 68.80 secs\n",
      "\n",
      "Epoch 2, Loss: 0.1048, Accuracy: 0.9718, Val_Loss: 0.0773, Val Accuracy: 0.9796\n",
      "Time taken for 1 epoch: 61.13 secs\n",
      "\n",
      "Epoch 3, Loss: 0.0712, Accuracy: 0.9806, Val_Loss: 0.0583, Val Accuracy: 0.9847\n",
      "Time taken for 1 epoch: 61.12 secs\n",
      "\n",
      "Epoch 4, Loss: 0.0573, Accuracy: 0.9842, Val_Loss: 0.0499, Val Accuracy: 0.9866\n",
      "Time taken for 1 epoch: 61.11 secs\n",
      "\n",
      "Epoch 5, Loss: 0.0473, Accuracy: 0.9869, Val_Loss: 0.0368, Val Accuracy: 0.9903\n",
      "Time taken for 1 epoch: 61.13 secs\n",
      "\n",
      "Epoch 6, Loss: 0.0385, Accuracy: 0.9895, Val_Loss: 0.0291, Val Accuracy: 0.9925\n",
      "Time taken for 1 epoch: 61.12 secs\n",
      "\n",
      "Epoch 7, Loss: 0.0307, Accuracy: 0.9916, Val_Loss: 0.0242, Val Accuracy: 0.9937\n",
      "Time taken for 1 epoch: 61.14 secs\n",
      "\n",
      "Epoch 8, Loss: 0.0250, Accuracy: 0.9932, Val_Loss: 0.0188, Val Accuracy: 0.9950\n",
      "Time taken for 1 epoch: 61.11 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS = 8\n",
    "history = {\n",
    "  \"epoch\": [],\n",
    "  \"loss\": [],\n",
    "  \"Accuracy\" :[],\n",
    "  \"val_loss\" :[],\n",
    "  \"val_Accuracy\" :[]\n",
    "}\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  total_loss = 0\n",
    "  val_loss = 0\n",
    "  # TRAIN LOOP\n",
    "  for (batch, (inp, tar)) in enumerate(train):\n",
    "      batch_loss = train_step(inp,tar)\n",
    "      total_loss = total_loss + batch_loss\n",
    "  history['epoch'].append(epoch)\n",
    "  history['loss'].append(total_loss/(batch+1))\n",
    "  history['Accuracy'].append(train_accuracy.result())  \n",
    "  for (batc, (inp, tar)) in enumerate(val):\n",
    "      batch_loss = val_step(inp,tar)\n",
    "      val_loss += batch_loss\n",
    "  history['val_loss'].append(val_loss/(batc+1))\n",
    "  history['val_Accuracy'].append(test_accuracy.result())  \n",
    "  if (epoch+1) % 1 == 0: \n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/(batch+1):.4f}, Accuracy: {train_accuracy.result():.4f}, Val_Loss: {val_loss/(batc+1):.4f}, Val Accuracy: {test_accuracy.result():.4f}') \n",
    "        print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n",
    "  train_accuracy.reset_states()\n",
    "  test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeL49AOPMDl2"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp):\n",
    "    logits = model(inp['input_ids'], token_type_ids=None, attention_mask=inp['attention_mask']).logits\n",
    "    predicted_id = tf.argmax(logits, axis=-1)\n",
    "    return logits, predicted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSJQ7V4-pIXJ",
    "outputId": "ff51b67f-c96f-48ee-a45d-b8a86aaeb8e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model on Test :  0.9948017\n",
      "Time taken for 1 epoch: 2.49 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for (batch, (inp, tar)) in enumerate(val):\n",
    "    x_test = inp\n",
    "    y_test = tar\n",
    "    logits,prob = evaluate(inp)\n",
    "    test_accuracy.update_state(tar, logits)\n",
    "print('Accuracy of model on Test : ', test_accuracy.result().numpy())\n",
    "print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ltGg_QmppfYn",
    "outputId": "0fde8227-d3bb-4ff6-afba-51adc448ffa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           True \t Pred\n",
      "\n",
      "------------------------------\n",
      "[CLS]          O\tO\n",
      "Em             O\tO\n",
      "##bed          O\tO\n",
      "##ded          O\tO\n",
      "reporters      O\tO\n",
      "in             O\tO\n",
      "Fall           B-geo\tB-geo\n",
      "##u            B-geo\tB-geo\n",
      "##jah          B-geo\tB-geo\n",
      "say            O\tO\n",
      "troops         O\tO\n",
      "searching      O\tO\n",
      "the            O\tO\n",
      "safe           O\tO\n",
      "house          O\tO\n",
      "property       O\tO\n",
      "found          O\tO\n",
      "photographs    O\tO\n",
      ",              O\tO\n",
      "notes          O\tO\n",
      ",              O\tO\n",
      "ammunition     O\tO\n",
      "and            O\tO\n",
      "letters        O\tO\n",
      "thought        O\tO\n",
      "to             O\tO\n",
      "be             O\tO\n",
      "from           O\tO\n",
      "al             B-per\tB-per\n",
      "-              B-per\tB-per\n",
      "Z              B-per\tB-per\n",
      "##ar           B-per\tB-per\n",
      "##qa           B-per\tB-per\n",
      "##wi           B-per\tB-per\n",
      ".              O\tO\n",
      "[SEP]          O\tO\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0, x_test['input_ids'].shape[0]) #659\n",
    "p = prob[i]\n",
    "y_true = y_test[i]\n",
    "print(\"{:15}{:5}\\t {}\\n\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(\"-\" *30)\n",
    "test = tokenizer.convert_ids_to_tokens(x_test['input_ids'][i])\n",
    "for w, true, pred in zip(test, y_true, p):\n",
    "    print(\"{:15}{}\\t{}\".format(w, indxtotag[true.numpy()], indxtotag[pred.numpy()]))\n",
    "    if w == '[SEP]':\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzoCereEr8E7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "NER_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
