{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLBHSm9Rje7d",
    "outputId": "97ffa005-4815-422e-e864-974363a87fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUxzpUasi0V7"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQJoa7WGyqfo",
    "outputId": "8093bd12-c3b6-418f-df52-0e73f3f59839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qx_ey3tYy1xs"
   },
   "outputs": [],
   "source": [
    "path = '/Bert_Base_Cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylDxj-oDB-0j"
   },
   "source": [
    "#Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Z5yF6SGi0WJ",
    "outputId": "fcd512cc-20a0-45f9-d5e2-21d76bbebd55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
      "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
      "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split None, from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,   as_supervised=True)\n",
    "\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzy-D8PuITdw"
   },
   "outputs": [],
   "source": [
    "dataset = test_dataset.concatenate(train_dataset) # Concanate tarin and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KvpAdp3IIyY"
   },
   "outputs": [],
   "source": [
    "# Select sentences with max seq len of 128\n",
    "max_length_word = 128\n",
    "min_length_word = 64\n",
    "def dataset_fn(ds):\n",
    "  return ds.filter(lambda x, y: len(tf.strings.split(x)) < max_length_word and len(tf.strings.split(x)) > min_length_word)\n",
    "dataset = dataset.apply(dataset_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "-38Y2MDLIcvo",
    "outputId": "9aa757c5-de70-4d1f-d225-291311ca800b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s.numpy().split()) for s,y in dataset],log=True, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfDYDr7yi0WL"
   },
   "outputs": [],
   "source": [
    "def data_to_numpy(data, num):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    i=0\n",
    "    for sentence, label in data:\n",
    "        sentences.append(str(sentence.numpy()))\n",
    "        labels.append(label.numpy())\n",
    "        i=i+1\n",
    "        if i >= num:\n",
    "            break\n",
    "    labels_np = np.array(labels)\n",
    "    \n",
    "    return sentences, labels_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eBj5FWgi0WO"
   },
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "training_sentences, training_labels = data_to_numpy(dataset, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NZd977lQi0WP",
    "outputId": "cb8cbcbe-2f13-4432-a1f9-ea7367cdb5a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = len(training_sentences)\n",
    "seq_len = 128\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XtVyYxBi0WU"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', cache_dir=path)\n",
    "# tokenize - this time returning Numpy tensors\n",
    "tokens = tokenizer(training_sentences, max_length=seq_len, truncation=True,\n",
    "                   padding='max_length', add_special_tokens=True, return_token_type_ids=False,\n",
    "                   return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bbfGPZzi0WY",
    "outputId": "f8e43247-ee3e-4ab2-afa6-8d0a2e6c310c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(10000, 128), dtype=int32, numpy=\n",
       "array([[ 101,  171,  112, ...,    0,    0,    0],\n",
       "       [ 101,  171,  107, ..., 2712,  119,  102],\n",
       "       [ 101,  171,  112, ..., 3202,  119,  102],\n",
       "       ...,\n",
       "       [ 101,  171,  107, ..., 1105, 1199,  102],\n",
       "       [ 101,  171,  112, ...,    0,    0,    0],\n",
       "       [ 101,  171,  112, ...,  165,  112,  102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(10000, 128), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssbo4VAUi0We"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = num_samples\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((tokens['input_ids'], tokens['attention_mask'], training_labels)).shuffle(BUFFER_SIZE)\n",
    "data = data.batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E34CiHt8i0Wg"
   },
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "data = data.map(map_func)\n",
    "SIZE = num_samples/BATCH_SIZE\n",
    "SPLIT = 0.9\n",
    "\n",
    "train = data.take(int(SIZE*SPLIT))\n",
    "val = data.skip(int(SIZE*SPLIT))\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BrWlIwii0Wl"
   },
   "source": [
    "---\n",
    "\n",
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gi8rmIDi0Wr"
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbMwz8JBi0Wt",
    "outputId": "3d04efa7-ff5d-4d55-e048-b91c8cf01f37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')  #, output_hidden_states=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FW86bveAi0Wu",
    "outputId": "46dd2dc9-1c3e-40f6-c6fd-678d0e8452ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhegtTV4i0Wv"
   },
   "outputs": [],
   "source": [
    "def build_model(transformer):\n",
    " \n",
    "    # Define weight initializer with a random seed to ensure reproducibility    \n",
    "    # Define input layers\n",
    "    input_ids_layer = tf.keras.layers.Input(shape=(seq_len,), \n",
    "                                            name='input_ids', \n",
    "                                            dtype='int32')\n",
    "    input_attention_layer = tf.keras.layers.Input(shape=(seq_len,), \n",
    "                                                  name='attention_mask', \n",
    "                                                  dtype='int32')\n",
    "    \n",
    "    # DistilBERT outputs a tuple where the first element at index 0\n",
    "    # represents the hidden-state at the output of the model's last layer.\n",
    "    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n",
    "    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[1]\n",
    "    \n",
    "    # We only care about DistilBERT's output for the [CLS] token, which is located\n",
    "    # at index 0.  Splicing out the [CLS] tokens gives us 2D data.\n",
    "    cls_token = last_hidden_state\n",
    "    \n",
    "    D1 = tf.keras.layers.Dropout(0.1)(cls_token)\n",
    "    \n",
    "    D2 = tf.keras.layers.Dropout(0.2\n",
    "                                )(D1)\n",
    "    \n",
    "    D3 = tf.keras.layers.Dense(32,\n",
    "                              activation='relu',\n",
    "                              )(D2)\n",
    "    \n",
    "    D4 = tf.keras.layers.Dropout(0.1\n",
    "                                )(D3)\n",
    "    \n",
    "    # Define a single node that makes up the output layer (for binary classification)\n",
    "    output = tf.keras.layers.Dense(1,  activation='sigmoid')(D4)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n",
    "    \n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=0.00001), \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5Nzh1Jgi0Wz"
   },
   "outputs": [],
   "source": [
    "# Freeze BERT layers to preserve pre-trained weights \n",
    "for layer in bert.layers:\n",
    "    layer.trainable = True\n",
    "model = build_model(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKUJJW97i0W1",
    "outputId": "b986bc1e-c7d7-4172-ddfe-0f62b6df118d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_4 (TFBertModel)  TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dropout_218 (Dropout)          (None, 768)          0           ['tf_bert_model_4[0][1]']        \n",
      "                                                                                                  \n",
      " dropout_219 (Dropout)          (None, 768)          0           ['dropout_218[0][0]']            \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 32)           24608       ['dropout_219[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_220 (Dropout)          (None, 32)           0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1)            33          ['dropout_220[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,334,913\n",
      "Trainable params: 108,334,913\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXOurSvZi0W6",
    "outputId": "68aa6895-e0f1-4df4-d7ef-1d870d8527af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "140/140 [==============================] - 151s 942ms/step - loss: 0.4079 - accuracy: 0.8029 - val_loss: 0.2313 - val_accuracy: 0.9183\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 129s 919ms/step - loss: 0.2277 - accuracy: 0.9172 - val_loss: 0.1200 - val_accuracy: 0.9673\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 129s 918ms/step - loss: 0.1670 - accuracy: 0.9445 - val_loss: 0.0884 - val_accuracy: 0.9740\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 129s 919ms/step - loss: 0.1222 - accuracy: 0.9621 - val_loss: 0.0743 - val_accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train,  validation_data=val, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pf6M4h0tPs8I"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJ26Qs3UJDCW"
   },
   "outputs": [],
   "source": [
    "# test the data\n",
    "def evaluate(sentence):\n",
    "  tokens = tokenizer(sentence, max_length=seq_len, truncation=True,\n",
    "                   padding='max_length', add_special_tokens=True, return_token_type_ids=False,\n",
    "                   return_tensors='tf')\n",
    "  output = model((tokens.input_ids, tokens.attention_mask))\n",
    "  if output > 0.5:\n",
    "     tag = \"Positive\"\n",
    "  else:\n",
    "     tag = \"Neagtive\"\n",
    "  return tag, output[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMNwjzw5MhTz",
    "outputId": "28858046-4e8b-458d-ac4f-15ac6bcd49d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above movie review : ('Neagtive', 0.15311772)\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The movie was bad, expected it to be good.'\n",
    "print(f'The above movie review : {evaluate(sentence)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BJPw-03NGke",
    "outputId": "8f20d937-1c42-47d5-e6cd-9890f6e48665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above movie review : ('Positive', 0.57513165)\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The movie was good, expected it to be bad.'\n",
    "print(f'The above movie review : {evaluate(sentence)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjbTuHJZN-iv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Sentimen_Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
