{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IOqFjm9AstnQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOqFjm9AstnQ",
    "outputId": "79f3ea95-2239-4411-e0b9-963597c1fa57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-confirmation",
   "metadata": {
    "id": "theoretical-confirmation"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i8Fdacqopppt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8Fdacqopppt",
    "outputId": "aa6afbdb-859e-497a-e6f5-c2013b79dc86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6PCVe_FZpncO",
   "metadata": {
    "id": "6PCVe_FZpncO"
   },
   "outputs": [],
   "source": [
    "path_data = '/squad'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TNJU4xA5CgIt",
   "metadata": {
    "id": "TNJU4xA5CgIt"
   },
   "source": [
    "#Load Squad Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-terry",
   "metadata": {
    "id": "touched-terry"
   },
   "outputs": [],
   "source": [
    "def read_squad(path, num_samples):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    # initialize lists for contexts, questions, and answers\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    # iterate through all data in squad data\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                if 'plausible_answers' in qa.keys():\n",
    "                    access = 'plausible_answers'\n",
    "                else:\n",
    "                    access = 'answers'\n",
    "                for answer in qa['answers']:\n",
    "                    # append data to lists\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "    # return formatted data lists\n",
    "    return contexts[:num_samples], questions[:num_samples], answers[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-treasury",
   "metadata": {
    "id": "little-treasury"
   },
   "outputs": [],
   "source": [
    "num_samples = 2000*16\n",
    "train_contexts, train_questions, train_answers = read_squad(path_data+'/train-v2.0.json', num_samples)\n",
    "val_contexts, val_questions, val_answers = read_squad(path_data+'/dev-v2.0.json', num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28d621-7131-4137-84e5-1463be78cc91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b28d621-7131-4137-84e5-1463be78cc91",
    "outputId": "e92e5aa5-9bbc-4685-dd5e-9a7c4d0d0f7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('in the late 1990s', 'When did Beyonce start becoming popular?', 32000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contexts[0][269:269+len(train_answers[0]['text'])], train_questions[0], len(train_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-zealand",
   "metadata": {
    "id": "handed-zealand"
   },
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-effect",
   "metadata": {
    "id": "voluntary-effect"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased-distilled-squad')\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YJPrEEwdVpsP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJPrEEwdVpsP",
    "outputId": "bcb193e5-59b8-48bf-ee0e-02e2360adbab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EIXCoWtTCjuP",
   "metadata": {
    "id": "EIXCoWtTCjuP"
   },
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, question, context, start_char_idx=None, answer_text=None, all_answers=None):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = answer_text\n",
    "        self.skip = False\n",
    "        self.start_token_idx = -1\n",
    "        self.end_token_idx = -1\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = \" \".join(str(self.context).split())\n",
    "        question = \" \".join(str(self.question).split()) #'max_length'\n",
    "        tokenized_context = tokenizer(context,question,truncation=True, padding=True, return_offsets_mapping=True)\n",
    "        if len(tokenized_context.input_ids) > 256:\n",
    "              return None\n",
    "        tokenized_context = tokenizer(context,question,max_length=256,truncation=True, padding='max_length', return_offsets_mapping=True)\n",
    "\n",
    "        if self.answer_text is not None:\n",
    "            answer = \" \".join(str(self.answer_text).split())\n",
    "            end_char_idx = self.start_char_idx + len(answer)\n",
    "            if end_char_idx >= len(context):\n",
    "                self.skip = True\n",
    "                return None\n",
    "            is_char_in_ans = [0] * len(context)\n",
    "            for idx in range(self.start_char_idx, end_char_idx):\n",
    "                is_char_in_ans[idx] = 1\n",
    "            ans_token_idx = []\n",
    "            for idx, (start, end) in enumerate(tokenized_context.offset_mapping):\n",
    "                if sum(is_char_in_ans[start:end]) > 0:\n",
    "                    ans_token_idx.append(idx)\n",
    "            if len(ans_token_idx) == 0:\n",
    "                self.skip = True\n",
    "                return None\n",
    "            self.start_token_idx = ans_token_idx[0]\n",
    "            self.end_token_idx = ans_token_idx[-1]\n",
    "         #, 'start_token_idx':self.start_token_idx, 'end_token_idx':self.end_token_idx  \n",
    "        return tokenized_context.input_ids , tokenized_context.attention_mask, self.start_token_idx, self.end_token_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ida4p3GRCyet",
   "metadata": {
    "id": "Ida4p3GRCyet"
   },
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_mask = []\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "for x ,(context, question, answer) in enumerate(zip(train_contexts, train_questions, train_answers)):\n",
    "        start_char_idx  = answer['answer_start']\n",
    "        answer_text = answer['text']\n",
    "        squad_eg = Sample(question, context, start_char_idx, answer_text)\n",
    "        x = squad_eg.preprocess()\n",
    "        if x==None:\n",
    "            continue\n",
    "        else :\n",
    "            input_ids.append(x[0])\n",
    "            attention_mask.append(x[1])\n",
    "            start_positions.append(x[2])\n",
    "            end_positions.append(x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A5xXPRGxCUBG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5xXPRGxCUBG",
    "outputId": "1b7ac773-e4fa-447e-db47-c52dd1025159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29094"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = len(input_ids)\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-daughter",
   "metadata": {
    "id": "specified-daughter"
   },
   "source": [
    "---\n",
    "\n",
    "# Fine-tuning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UBjxSPFiKp_3",
   "metadata": {
    "id": "UBjxSPFiKp_3"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = num_samples\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((input_ids, attention_mask,start_positions,end_positions)).shuffle(BUFFER_SIZE)\n",
    "data = data.batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k1XsChSoMzZ4",
   "metadata": {
    "id": "k1XsChSoMzZ4"
   },
   "outputs": [],
   "source": [
    "SIZE = num_samples/BATCH_SIZE\n",
    "SPLIT = 0.9\n",
    "def map_func(input_ids, masks, start_positions, end_positions):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks, 'start_positions' : start_positions, 'end_positions':end_positions}\n",
    "  \n",
    "data = data.map(map_func)\n",
    "\n",
    "train = data.take(int(SIZE*SPLIT))\n",
    "val = data.skip(int(SIZE*SPLIT))\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-qatar",
   "metadata": {
    "id": "alive-qatar"
   },
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertForQuestionAnswering, AdamWeightDecay\n",
    "model = TFDistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60Wd1gn4nYRb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60Wd1gn4nYRb",
    "outputId": "548ee7c1-a3c5-4883-d226-dedec1396963"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZPGWUKYXMXFR",
   "metadata": {
    "id": "ZPGWUKYXMXFR"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jNQLLEIeMZ8y",
   "metadata": {
    "id": "jNQLLEIeMZ8y"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp):\n",
    "  with tf.GradientTape() as tape:\n",
    "        input_ids = inp['input_ids']\n",
    "        attention_mask = inp['attention_mask']\n",
    "        start_positions = inp['start_positions']\n",
    "        end_positions = inp['end_positions']\n",
    "        # train model on batch and return outputs (incl. loss)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions,training=True)\n",
    "        loss = outputs[0][0]\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  return loss\n",
    "def val_step(inp):\n",
    "        input_ids = inp['input_ids']\n",
    "        attention_mask = inp['attention_mask']\n",
    "        start_positions = inp['start_positions']\n",
    "        end_positions = inp['end_positions']\n",
    "        # train model on batch and return outputs (incl. loss)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,  start_positions=start_positions,end_positions=end_positions)\n",
    "        loss = outputs[0][0]\n",
    "        return loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IOKOamuQM541",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOKOamuQM541",
    "outputId": "9054e642-0fbe-4e72-f2b6-58b651abd85f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 409/409 [06:11<00:00,  1.10it/s, loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0124, Val_Loss: 1.9777\n",
      "Time taken for 1 epoch: 385.14 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 409/409 [06:06<00:00,  1.12it/s, loss=0.441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.9975, Val_Loss: 1.9757\n",
      "Time taken for 1 epoch: 379.44 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 409/409 [06:06<00:00,  1.12it/s, loss=3.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.9201, Val_Loss: 1.6532\n",
      "Time taken for 1 epoch: 379.44 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 409/409 [06:05<00:00,  1.12it/s, loss=1.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.8982, Val_Loss: 2.0173\n",
      "Time taken for 1 epoch: 379.28 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 409/409 [06:06<00:00,  1.12it/s, loss=4.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.8527, Val_Loss: 1.9521\n",
      "Time taken for 1 epoch: 379.38 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "EPOCHS = 5\n",
    "history = {\n",
    "  \"epoch\": [],\n",
    "  \"loss\": [],\n",
    "  \"Accuracy\" :[],\n",
    "  \"val_loss\" :[],\n",
    "  \"val_Accuracy\" :[]\n",
    "}\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  total_loss = 0\n",
    "  val_loss = 0\n",
    "  # TRAIN LOOP\n",
    "  loop = tqdm(train, leave=True)\n",
    "  for (batch, (inp)) in enumerate(loop):\n",
    "      batch_loss = train_step(inp)\n",
    "      total_loss = total_loss + batch_loss\n",
    "      loop.set_description(f'Epoch {epoch+1}')\n",
    "      loop.set_postfix(loss=batch_loss.numpy())\n",
    "  history['epoch'].append(epoch)\n",
    "  history['loss'].append(total_loss/(batch+1))\n",
    "  for (batc, (inp)) in enumerate(val):\n",
    "      batch_loss = val_step(inp)\n",
    "      val_loss += batch_loss\n",
    "  history['val_loss'].append(val_loss/(batc+1))\n",
    "  if (epoch+1) % 1 == 0: \n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/(batch+1):.4f}, Val_Loss: {val_loss/(batc+1):.4f}') \n",
    "        print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fn82Xm5ZOqBR",
   "metadata": {
    "id": "Fn82Xm5ZOqBR"
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "for inp in val:\n",
    "        input_ids = inp['input_ids']\n",
    "        attention_mask = inp['attention_mask']\n",
    "        start_positions = inp['start_positions']\n",
    "        end_positions = inp['end_positions']\n",
    "        # train model on batch and return outputs (incl. loss)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,  start_positions=start_positions,end_positions=end_positions)\n",
    "        start_pred = tf.argmax(outputs['start_logits'], axis=1)\n",
    "        end_pred = tf.argmax(outputs['end_logits'], axis=1)\n",
    "        # calculate accuracy for both and append to accuracy list\n",
    "        acc.append(((start_pred.numpy() == start_positions.numpy()).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred.numpy() == end_positions.numpy()).sum()/len(end_pred)).item())\n",
    "# calculate average accuracy in total\n",
    "acc = sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EHN0j-rxcSDN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHN0j-rxcSDN",
    "outputId": "a71c8130-bab6-4b9a-8645-3cf6860480fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.561945795194508"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MUbo9-rocaSw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUbo9-rocaSw",
    "outputId": "a646092d-df7f-424a-9014-5d16792c06e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T/F\tstart\tend\n",
      "\n",
      "true\t60\t61\n",
      "pred\t60\t61\n",
      "\n",
      "true\t6\t201\n",
      "pred\t6\t201\n",
      "\n",
      "true\t25\t25\n",
      "pred\t25\t25\n",
      "\n",
      "true\t26\t29\n",
      "pred\t28\t29\n",
      "\n",
      "true\t100\t101\n",
      "pred\t99\t101\n",
      "\n",
      "true\t22\t24\n",
      "pred\t22\t24\n",
      "\n",
      "true\t36\t36\n",
      "pred\t36\t36\n",
      "\n",
      "true\t84\t86\n",
      "pred\t84\t86\n",
      "\n",
      "true\t39\t44\n",
      "pred\t39\t43\n",
      "\n",
      "true\t76\t76\n",
      "pred\t76\t80\n",
      "\n",
      "true\t36\t38\n",
      "pred\t40\t43\n",
      "\n",
      "true\t84\t86\n",
      "pred\t111\t86\n",
      "\n",
      "true\t89\t93\n",
      "pred\t83\t84\n",
      "\n",
      "true\t32\t40\n",
      "pred\t39\t40\n",
      "\n",
      "true\t103\t105\n",
      "pred\t103\t105\n",
      "\n",
      "true\t14\t22\n",
      "pred\t7\t12\n",
      "\n",
      "true\t20\t20\n",
      "pred\t28\t30\n",
      "\n",
      "true\t44\t45\n",
      "pred\t44\t83\n",
      "\n",
      "true\t183\t183\n",
      "pred\t41\t41\n",
      "\n",
      "true\t68\t68\n",
      "pred\t68\t68\n",
      "\n",
      "true\t59\t59\n",
      "pred\t59\t63\n",
      "\n",
      "true\t82\t83\n",
      "pred\t81\t83\n",
      "\n",
      "true\t89\t91\n",
      "pred\t108\t110\n",
      "\n",
      "true\t35\t35\n",
      "pred\t35\t35\n",
      "\n",
      "true\t17\t21\n",
      "pred\t52\t55\n",
      "\n",
      "true\t18\t18\n",
      "pred\t18\t18\n",
      "\n",
      "true\t9\t224\n",
      "pred\t55\t56\n",
      "\n",
      "true\t17\t17\n",
      "pred\t16\t17\n",
      "\n",
      "true\t59\t62\n",
      "pred\t1\t62\n",
      "\n",
      "true\t56\t58\n",
      "pred\t56\t57\n",
      "\n",
      "true\t2\t64\n",
      "pred\t2\t2\n",
      "\n",
      "true\t33\t33\n",
      "pred\t33\t33\n",
      "\n",
      "true\t57\t58\n",
      "pred\t56\t58\n",
      "\n",
      "true\t62\t63\n",
      "pred\t62\t63\n",
      "\n",
      "true\t151\t152\n",
      "pred\t8\t26\n",
      "\n",
      "true\t41\t42\n",
      "pred\t41\t15\n",
      "\n",
      "true\t31\t31\n",
      "pred\t31\t31\n",
      "\n",
      "true\t140\t144\n",
      "pred\t140\t38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"T/F\\tstart\\tend\\n\")\n",
    "for i in range(len(start_positions)):\n",
    "    print(f\"true\\t{start_positions[i]}\\t{end_positions[i]}\\n\"\n",
    "          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M0UtKt3mFLEN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M0UtKt3mFLEN",
    "outputId": "d154d318-458e-4d68-c26f-3dc543de6b51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question : how many paper cups are used by americans each year?\n",
      "Actual answer : 16 billion\n",
      "Predicted answer : 16 billion\n",
      "\n",
      "Question : john was deeply suspicious of who?\n",
      "Actual answer : the barons , particularly those with sufficient power and wealth to potentially challenge the king . numerous barons were subjected to john ' s male ##vo ##lent ##ia , even including william marshal , a famous knight and baron normally held up as a model of utter loyalty . the most infamous case , which went beyond anything considered acceptable at the time , proved to be that of william de bra ##ose , a powerful marche ##r lord with lands in ireland . de bra ##ose was subjected to pun ##itive demands for money , and when he refused to pay a huge sum of 40 , 000 marks ( equivalent to £2 ##6 , 66 ##6 at the time ) , [ n ##b 13 ] his wife and one of his sons were imprisoned by john , which resulted in their deaths . de bra ##ose died in exile in 121 ##1 , and his grandson ##s remained in prison until 121 ##8 . john ' s suspicions and jealous ##ies meant that he rarely enjoyed good relationships with even the leading loyalist barons . [SEP] john was deeply suspicious of who ?\n",
      "Predicted answer : the barons, particularly those with sufficient power and wealth to potentially challenge the king. numerous barons were subjected to john's malevolentia, even including william marshal, a famous knight and baron normally held up as a model of utter loyalty. the most infamous case, which went beyond anything considered acceptable at the time, proved to be that of william de braose, a powerful marcher lord with lands in ireland. de braose was subjected to punitive demands for money, and when he refused to pay a huge sum of 40, 000 marks ( equivalent to £26, 666 at the time ), [ nb 13 ] his wife and one of his sons were imprisoned by john, which resulted in their deaths. de braose died in exile in 1211, and his grandsons remained in prison until 1218. john's suspicions and jealousies meant that he rarely enjoyed good relationships with even the leading loyalist barons. [SEP] john was deeply suspicious of who?\n",
      "\n",
      "Question : how many doctors saw frederic by the 3rd of december?\n",
      "Actual answer : three\n",
      "Predicted answer : three\n",
      "\n",
      "Question : how many copies of the book have been sold?\n",
      "Actual answer : more than 30 million\n",
      "Predicted answer : 30 million\n",
      "\n",
      "Question : in some political models like semi - presidential systems, what does the prime minister manage?\n",
      "Actual answer : civil service\n",
      "Predicted answer : the civil service\n",
      "\n",
      "Question : near what town did the rsfsr annex territory in 1944?\n",
      "Actual answer : ivan ##gor ##od\n",
      "Predicted answer : ivangorod\n",
      "\n",
      "Question : what country found bank accounts and real estate owned by the sassou regime?\n",
      "Actual answer : france\n",
      "Predicted answer : france\n",
      "\n",
      "Question : what program did creative join in order to make ipod peripherals?\n",
      "Actual answer : made for ipod\n",
      "Predicted answer : made for ipod\n",
      "\n",
      "Question : what two dignitaries where at his first performance in london?\n",
      "Actual answer : queen victoria and prince albert .\n",
      "Predicted answer : queen victoria and prince albert\n",
      "\n",
      "Question : being exposed to what type of pollution has been theorized to increase aggression?\n",
      "Actual answer : lead\n",
      "Predicted answer : lead pollution from automobile exhaust\n",
      "\n",
      "Question : which actress portrayed eve moneypenny?\n",
      "Actual answer : naomi ##e harris\n",
      "Predicted answer : ben whishaw\n",
      "\n",
      "Question : who suggested that jesus was the son of a roman soldier?\n",
      "Actual answer : ce ##ls ##us\n",
      "Predicted answer : \n",
      "\n",
      "Question : what advertising demographic is soft adult contemporary marketed towards?\n",
      "Actual answer : females aged 25 – 54\n",
      "Predicted answer : office workers\n",
      "\n",
      "Question : for best fidelity to the source, what three things should match the source?\n",
      "Actual answer : transmitted field ratio , lines , and frame rate\n",
      "Predicted answer : frame rate\n",
      "\n",
      "Question : what do brewing companies sometimes use to give more alcohol content to their beer?\n",
      "Actual answer : champagne yeast ##s\n",
      "Predicted answer : champagne yeasts\n",
      "\n",
      "Question : what happens in polygynous species with sexual dimophism?\n",
      "Actual answer : males tend to return earlier to the breeding sites\n",
      "Predicted answer : considerable sexual dimorphism\n",
      "\n",
      "Question : which year did the ussr cancel the n1 rocket program after two failures that didn't launch?\n",
      "Actual answer : 1976\n",
      "Predicted answer : 1971 and 1972\n",
      "\n",
      "Question : in what year did pope sixtus v put a cap on the number of cardinals in the college of cardinals?\n",
      "Actual answer : 158 ##7\n",
      "Predicted answer : 1587, pope sixtus v sought to arrest this growth by fixing the maximum size of the college at 70, including 50 cardinal priests, about twice the historical number. this limit was respected until 1958\n",
      "\n",
      "Question : how many children does the protagonist, atticus finch, have?\n",
      "Actual answer : two\n",
      "Predicted answer : six\n",
      "\n",
      "Question : when did mawson retire after leading several expeditions?\n",
      "Actual answer : 1931\n",
      "Predicted answer : 1931\n",
      "\n",
      "Question : what language family did common brittonic belong to?\n",
      "Actual answer : celtic\n",
      "Predicted answer : celtic language, and latin\n",
      "\n",
      "Question : what american naval officer led a raid that destroyed a captured american ship?\n",
      "Actual answer : stephen decatur\n",
      "Predicted answer : lieutenant stephen decatur\n",
      "\n",
      "Question : who did the emperor give the place of honor at his left to?\n",
      "Actual answer : the karma ##pa\n",
      "Predicted answer : karma thinley\n",
      "\n",
      "Question : in what year did the delhi flying club begin operations?\n",
      "Actual answer : 1929\n",
      "Predicted answer : 1929\n",
      "\n",
      "Question : what did cerberus guard?\n",
      "Actual answer : the gates of hades .\n",
      "Predicted answer : the chinvat bridge\n",
      "\n",
      "Question : when was ceefax launched?\n",
      "Actual answer : 1974\n",
      "Predicted answer : 1974\n",
      "\n",
      "Question : at what conventions did microsoft announce iptv support through the 360?\n",
      "Actual answer : consumer electronics shows , microsoft had announced that ip ##tv services would soon be made available to use through the xbox 360 . in 2007 , microsoft chairman bill gates stated that ip ##tv on xbox 360 was expected to be available to consumers by the holiday season , using the microsoft tv ip ##tv edition platform . in 2008 , gates and president of entertainment & devices robbie bach announced a partnership with bt in the united kingdom , in which the bt vision advanced tv service , using the newer microsoft media ##room ip ##tv platform , would be accessible via xbox 360 , planned for the middle of the year . bt vision ' s d ##vr - based features would not be available on xbox 360 due to limited hard drive capacity . in 2010 , while announcing version 2 . 0 of microsoft media ##room , microsoft ceo steve ball ##mer mentioned that at & t ' s u - verse ip ##tv service would enable xbox 360 ##s to be used as set - top boxes later in the year . as of january 2010 , ip ##tv on xbox 360 has yet to be deployed beyond limited trials . [SEP] at what conventions did microsoft announce ip ##tv support\n",
      "Predicted answer : holiday season\n",
      "\n",
      "Question : when did the everton club board fire smith?\n",
      "Actual answer : 2002\n",
      "Predicted answer : march 2002\n",
      "\n",
      "Question : which mobile carrier became a sponsor of american idol in its second season?\n",
      "Actual answer : at & t wireless\n",
      "Predicted answer : ford motor company and coca - cola were two of the first sponsors of american idol in its first season. the sponsorship deal cost around $ 10 million in season one, rising to $ 35 million by season 7, and between $ 50 to $ 60 million in season 10. the third major sponsor at & t wireless\n",
      "\n",
      "Question : which countries experienced a decrease in hdi?\n",
      "Actual answer : high income countries\n",
      "Predicted answer : high income\n",
      "\n",
      "Question : how many nocturnes did chopin compose?\n",
      "Actual answer : 21 no ##ct ##urne ##s are more structured , and of greater emotional depth , than those of field ( whom chopin met in 1833 ) . many of the chopin no ##ct ##urne ##s have middle sections marked by agitated expression ( and often making very difficult demands on the performer ) which height ##ens their dramatic character . [SEP] how many\n",
      "Predicted answer : 21\n",
      "\n",
      "Question : in what year did michel foucalt publish the history of sexuality?\n",
      "Actual answer : 1976\n",
      "Predicted answer : 1976\n",
      "\n",
      "Question : the top browsers have a built - in what?\n",
      "Actual answer : feed aggregator\n",
      "Predicted answer : web feed aggregator\n",
      "\n",
      "Question : where is nazareth located?\n",
      "Actual answer : northern israel\n",
      "Predicted answer : northern israel\n",
      "\n",
      "Question : how was rag paper superior to the early types of paper made using alum?\n",
      "Actual answer : more stable\n",
      "Predicted answer : wood pulp contained significant amounts of alum, a variety of aluminium sulfate salts that is significantly acidic\n",
      "\n",
      "Question : what language forms are not now used in eastern catalonia?\n",
      "Actual answer : traditional ones\n",
      "Predicted answer : \n",
      "\n",
      "Question : where do bar - tailed godwits migrate from\n",
      "Actual answer : alaska\n",
      "Predicted answer : alaska\n",
      "\n",
      "Question : what was the charity that liszt and chopin last performed for?\n",
      "Actual answer : the beethoven memorial in bonn\n",
      "Predicted answer : \n"
     ]
    }
   ],
   "source": [
    "asd = {}\n",
    "for i in range(len(start_positions)):\n",
    "    start = None\n",
    "    end = None\n",
    "    for j, x in enumerate(input_ids[i]):\n",
    "        if x == 102 and start == None:\n",
    "           start = j\n",
    "        if x == 0 and end == None:\n",
    "           end = j\n",
    "    print(f\"\\nQuestion : {(tokenizer.decode(input_ids[i][start+1:end-1]))}\")\n",
    "    print(f\"Actual answer : {' '.join(tokenizer.convert_ids_to_tokens(input_ids[i])[start_positions[i]:end_positions[i]+1])}\")\n",
    "    print(f\"Predicted answer : {tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i]+1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sT6zYflP5jIw",
   "metadata": {
    "id": "sT6zYflP5jIw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Question_Answer_Squad_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
